\section{Méthodologie de Spécification Architecturale}
Pour sp\'ecifier une architecture d\'edi\'ee \`a un nouveau domaine (par exemple l’intelligence artificielle ou le traitement vid\'eo), nous proposons la m\'ethodologie rigoureuse suivante, d\'eriv\'ee de l’exp\'erience acquise lors de ce TP :

\begin{enumerate}
  \item \textbf{Caract\'erisation de la charge (\emph{profiling}).} Utiliser des outils comme Gem5 (mode atomique) pour extraire le ``mix d'instructions''.
  
  \textit{Objectif :} identifier si l’application est \emph{compute-bound} (n\'ecessitant des ALU/FPU plus larges) ou \emph{memory-bound} (n\'ecessitant des caches et de la bande passante).

  \item \textbf{Exploration de l’espace de conception (\emph{Design Space Exploration}, DSE).} Automatiser les simulations (via des scripts Python/Bash comme dans ce TP) en faisant varier les param\`etres critiques : taille de cache, largeur de pipeline (\emph{issue width}), pr\'edicteurs de branchement. Mesurer l’IPC pour chaque point.

  \item \textbf{Contraintes physiques (PPA : \emph{Power, Performance, Area}).} Mod\'eliser chaque configuration retenue avec un outil physique comme CACTI~7.0 (pour la surface et la latence) et McPAT (pour la puissance). Rejeter les configurations irr\'ealistes (par exemple, latence $>1$ cycle).

  \item \textbf{Analyse de Pareto et choix final.} Tracer les courbes de compromis (par exemple, performance vs surface). S\'electionner les points du front de Pareto : ceux qui offrent le meilleur gain de performance pour un co\^ut marginal en surface/\`energie acceptable. \`A titre d’exemple dans ce TP, le passage de 16~kB \`a 32~kB sur le Cortex-A15 \'etait sur le front de Pareto (gain tr\`es important), alors que sur le Cortex-A7 il ne l’\'etait pas (gain n\'egligeable).
\end{enumerate}

\section{Compromis et conclusion}

Les configurations proposées ne sont pas strictement équivalentes au sens où elles ne mènent pas au même choix de taille $L1$ pour toutes les applications et pour tous les clusters. Le dimensionnement optimal dépend à la fois (i) de la nature de l’application et de sa sensibilité à la hiérarchie mémoire, et (ii) de l’objectif de conception du cluster considéré (\emph{little} orienté coût/énergie vs \emph{big} orienté performance). Ainsi, on observe que Dijkstra et Blowfish ne conduisent pas aux mêmes compromis sur Cortex-A7, alors qu’elles convergent vers une même configuration sur Cortex-A15.

Pour Dijkstra sur le cluster \emph{little} (Cortex-A7), la configuration retenue est $16$~kB en I-cache et $16$~kB en D-cache, car elle maximise l’efficacité énergétique et l’efficacité surfacique pour les versions \emph{Small} et \emph{Large}. Néanmoins, l’analyse de performance met en évidence un point d’inflexion autour de $8$~kB : le gain d’IPC entre $8$~kB et $16$~kB reste faible et la progression tend à saturer. Par conséquent, un compromis alternatif cohérent consiste à considérer $8$~kB comme une option possible si d’autres contraintes dominent (coût de fabrication, budget surface, intégration), puisque les performances simulées et les indicateurs d’efficacité restent proches entre $8$~kB et $16$~kB. Autrement dit, $16$~kB est recommandé par les métriques d’efficacité, mais $8$~kB peut être défendu par l’argument de saturation de l’IPC et par une logique de minimisation de ressources sur le cluster \emph{little}.

Pour Dijkstra sur le cluster \emph{big} (Cortex-A15), la configuration recommandée est $32$~kB pour la I-cache et $32$~kB pour la D-cache. Ce choix est motivé par le fait qu’il fournit simultanément la meilleure efficacité surfacique et la meilleure efficacité énergétique parmi les configurations évaluées, tout en maximisant le gain d’IPC. De plus, la réduction des pertes, en particulier en D-cache, constitue la source principale du gain d’IPC, et la diminution de ces pertes n’apparaît pas totalement saturée à $32$~kB, ce qui renforce la pertinence de cette taille sur le cluster \emph{big}.

Pour Blowfish sur le cluster \emph{little} (Cortex-A7), les critères d’efficacité surfacique et énergétique pointent vers des tailles différentes (respectivement $8$~kB et $16$~kB). Le choix final se fait alors en intégrant le comportement en performance : l’IPC présente un point d’inflexion dès $8$~kB et l’augmentation de taille au-delà n’apporte plus de gains significatifs, tandis que la diminution des pertes en I-cache et D-cache sature également. Par conséquent, $8$~kB en I-cache et $8$~kB en D-cache est retenu comme compromis le plus rationnel au regard des performances applicatives et du rôle « frugal » attendu du cluster \emph{little}. Pour Blowfish sur le cluster \emph{big} (Cortex-A15), la recommandation est à nouveau $32$~kB/$32$~kB, car cette taille maximise les efficacités surfacique et énergétique et reste cohérente avec une hausse d’IPC qui continue jusqu’à $32$~kB, supérieure à celle obtenue avec $16$~kB.

En conclusion, les configurations proposées ne sont donc pas équivalentes au sens d’un choix unique et invariant : sur Cortex-A7, Dijkstra pousse vers $16$~kB (avec l’alternative défendable de $8$~kB compte tenu de la saturation de l’IPC), tandis que Blowfish se contente de $8$~kB ; sur Cortex-A15, les deux applications convergent vers $32$~kB. Ce résultat est cohérent avec l’idée que Dijkstra demeure plus sensible à la hiérarchie mémoire et que Blowfish atteint plus rapidement un plateau de performance, et il justifie une stratégie big.LITTLE où le cluster \emph{big} est dimensionné pour capter les gains de performance, tandis que le cluster \emph{little} privilégie des tailles proches du point d’inflexion afin d’optimiser le coût et l’efficacité.
