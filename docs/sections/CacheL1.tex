\subsection{Impact de la taille des caches L1}

Les Figs. (\ref{fig:dijkstra-l1-perf})-(\ref{fig:dijkstra-l1-branch}) et (\ref{fig:blowfish-l1-perf})-(\ref{fig:blowfish-l1-branch}) présentent l’évolution des performances en fonction de la taille du cache L1 pour dijkstra applications et pour Blowfish applications respectivement. 

\begin{figure}[h]
\centering
\subfloat[CPI (A7).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/cpi_bar.png}}
\subfloat[IPC (A7).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/ipc_bar.png}}
\subfloat[Cycles (A7).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/numCycles_bar.png}}\\
\subfloat[CPI (A15).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/cpi_bar.png}}
\subfloat[IPC (A15).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/ipc_bar.png}}
\subfloat[Cycles (A15).]{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/numCycles_bar.png}}
\caption{Dijkstra : performance générale en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:dijkstra-l1-perf}
\end{figure}


\begin{figure}[h]
\centering
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/icache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/dcache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/l2_miss_bar.png}}\\
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/icache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/dcache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/l2_miss_bar.png}}
\caption{Dijkstra : taux de défauts I-Cache, D-Cache et L2 en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:dijkstra-l1-mem}
\end{figure}


\begin{figure}[h]
\centering
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/bp_cond_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/bp_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A7/btb_hit_ratio_bar.png}}\\
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/bp_cond_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/bp_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../dijkstra/plots_L1_A15/btb_hit_ratio_bar.png}}
\caption{Dijkstra : métriques de prédiction de branchement en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:dijkstra-l1-branch}
\end{figure}

\begin{figure}[h]
\centering
\subfloat[CPI (A7).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/cpi_bar.png}}
\subfloat[IPC (A7).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/ipc_bar.png}}
\subfloat[Cycles (A7).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/numCycles_bar.png}}\\
\subfloat[CPI (A15).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/cpi_bar.png}}
\subfloat[IPC (A15).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/ipc_bar.png}}
\subfloat[Cycles (A15).]{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/numCycles_bar.png}}
\caption{Blowfish : performance générale en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:blowfish-l1-perf}
\end{figure}

\begin{figure}[h]
\centering
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/icache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/dcache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/l2_miss_bar.png}}\\
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/icache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/dcache_miss_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/l2_miss_bar.png}}
\caption{Blowfish : taux de défauts I-Cache, D-Cache et L2 en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:blowfish-l1-mem}
\end{figure}

\begin{figure}[h]
\centering
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/bp_cond_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/bp_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A7/btb_hit_ratio_bar.png}}\\
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/bp_cond_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/bp_mispredict_rate_bar.png}}
\subfloat{\includegraphics[width=0.32\linewidth]{../blowfish/plots_L1_A15/btb_hit_ratio_bar.png}}
\caption{Blowfish : métriques de prédiction de branchement en fonction de la taille du cache L1 (A7 en haut, A15 en bas).}
\label{fig:blowfish-l1-branch}
\end{figure} 

Pour les impl\'ementations sur Cortex-A7, et plus particuli\`erement dans le cas des applications bas\'ees sur l’algorithme de Dijkstra, on observe, aussi bien pour le \emph{large} que pour le \emph{small}, une zone critique comprise entre 1~kB et 4~kB, dans laquelle les gains d’IPC li\'es \`a l’augmentation de la taille du cache L1 sont rapides. Cette zone correspond \`a la transition entre un L1 trop petit pour contenir les principales structures de donn\'ees, et un L1 suffisamment grand pour supporter les acc\`es r\'ep\'et\'es, principalement sur les donn\'ees, au cours de l’ex\'ecution de l’application.

On constate qu’\`a 8~kB appara\^it un point d’inflexion, o\`u l’am\'elioration continue et atteint le saut de performance le plus notable par rapport \`a la taille de L1 pr\'ec\'edente. De plus, on observe que les am\'eliorations du cache d’instructions commencent \`a saturer, en atteignant un niveau de pertes minimal et un gain proche de 100\% par rapport \`a la configuration avec un L1 de 1~kB. Parall\`element, la diminution des pertes dans le cache de donn\'ees est la plus significative parmi les intervalles consid\'er\'es, puis elle commence \`a montrer un comportement de saturation en suivant la trajectoire des gains.

Enfin, cette saturation se consolide vers 16~kB, o\`u les gains d’IPC dus \`a l’augmentation de la taille du L1 deviennent marginaux, et o\`u la r\'eduction des d\'efauts n’apporte plus que des am\'eliorations modestes. Ce comportement est coh\'erent avec la micro-architecture A7, qui poss\`ede des buffers plus modestes et une largeur d’ex\'ecution plus r\'eduite : lorsque le L1 est trop petit, chaque d\'efaut se traduit par un blocage visible de la cha\^\i ne de traitement, mais d\`es que les structures de travail tiennent majoritairement dans le cache, les limites se d\'eplacent vers le d\'ebit de calcul plut\^ot que vers la m\'emoire. Il convient \'egalement de souligner qu’il devient \'evident qu’il existe une d\'ependance entre l’impact des branchements et la taille du cache L1. Ce r\'esultat est attendu, dans la mesure o\`u le comportement des branchements d\'epend du pr\'edicteur de branchement.

De mani\`ere compl\'ementaire, on voit que, dans le cas du Dijkstra \emph{small}, la perte de cache de donn\'ees est plus faible que pour le \emph{large}, ce qui est un r\'esultat attendu, puisque, pour le \emph{large}, le \emph{working set} de donn\'ees d\'epasse plus rapidement la capacit\'e minimale, ce qui accentue les d\'efauts pour les petites tailles. Il faut aussi tenir compte de la taille de ligne de 32~octets sur A7 : ce choix favorise la localit\'e spatiale sans trop p\'enaliser les conflits, mais il limite la quantit\'e de donn\'ees captur\'ees par chaque remplissage, ce qui rend les petites tailles de cache plus sensibles aux acc\`es \`a pas irr\'egulier.

L’associativit\'e 2-ways r\'eduit une partie des conflits, mais elle ne suffit pas \`a \'eliminer les collisions lorsque des structures cha\^\i n\'ees ou des tables de distances sont activement parcourues ; l’augmentation de la taille agit donc \`a la fois sur la capacit\'e et sur la probabilit\'e de conflit, d’o\`u la baisse rapide des d\'efauts dans la zone critique. On observe aussi que l’am\'elioration de la I-cache est plus rapide que celle de la D-cache, ce qui confirme que, pour Dijkstra, la performance est principalement limit\'ee par les donn\'ees et non par l’\emph{instruction fetch}, une fois que le code chaud est captur\'e.


De son c\^ot\'e, dans le cas de Blowfish sur le m\^eme Cortex-A7, la compacit\'e du code et la localit\'e des donn\'ees exploit\'ees par l’algorithme ont un effet clair sur la dynamique de diminution des pertes, principalement au niveau du cache de donn\'ees, en comparaison avec la dynamique observ\'ee pour Dijkstra. Aussi bien pour Blowfish \emph{large} que pour Blowfish \emph{small}, on met en \'evidence une zone critique d’am\'elioration lorsque la taille du cache augmente de 1~kB \`a 4~kB.

On observe \'egalement une zone d’inflexion marqu\'ee autour d’une taille de 8~kB, pour laquelle on atteint la plus grande diff\'erence en gain d’IPC et la plus forte diminution des pertes, en particulier pour le cache de donn\'ees, par rapport \`a la taille de cache imm\'ediatement pr\'ec\'edente. Au-del\`a de 8~kB, une saturation du syst\`eme devient visible, avec des gains d’IPC marginaux et pratiquement n\'egligeables. Cette dynamique, comme dans le cas de Dijkstra, est d\'etermin\'ee par la saturation des diminutions de pertes en cache.

N\'eanmoins, en raison des conditions d\'ej\`a mentionn\'ees de localit\'e et des modes d’acc\`es et de stockage en m\'emoire propres \`a cet algorithme, on constate que, du c\^ot\'e du cache d’instructions, le niveau de saturation est atteint pour des tailles de cache plus petites. De plus, pour les pertes du cache de donn\'ees, Blowfish obtient de meilleurs r\'esultats que Dijkstra \`a taille de cache identique, en atteignant une diminution de 90{,}44\% par rapport \`a l’architecture avec un L1 de 1~kB. L’effet de la taille du cache sur les branchements, comme dans le cas de Dijkstra, ne pr\'esente pas de relation directe avec la taille du cache.

Une observation que l’on peut formuler concernant le comportement des algorithmes pour diff\'erentes tailles de cache est qu’elle met en \'evidence que le goulot d’\'etranglement de l’impl\'ementation n’\'etait pas n\'ecessairement li\'e aux limitations m\'emoire. En effet, en ne faisant varier que les caches, on atteint une saturation des am\'eliorations d’IPC pour des valeurs proches de seulement 20\% par rapport \`a la configuration de base, tandis que la variation r\'esultant du traitement du parall\'elisme sur A15, compar\'e \`a A7, produit des r\'esultats beaucoup plus importants en termes d’IPC.

Ce constat renforce l’appr\'eciation initiale selon laquelle la classe dominante d’instructions dans les applications correspond effectivement aux op\'erations de calcul entier. On propose donc d’analyser les comportements des algorithmes sur Cortex-A15 afin d’\'evaluer l’hypoth\`ese formul\'ee.

En somme, en tenant compte de l’effet de saturation observ\'e en fonction de la taille du L1, la configuration retenue est de 8~kB. Il s’agit du ``sweet spot'' offrant le meilleur compromis performance/surface pour ce profil architectural, et ce, pour les deux applications.

\input{sections/CacheL1_gains_tables.tex}

Pour le Cortex-A15, les tendances observ\'ees, une fois l’optimisation du traitement des op\'erations du c\oe{}ur d\'ej\`a mise en place, deviennent plus marqu\'ees : la comparaison de l’IPC entre les deux Cortex (A15 et A7) montre des gains plus \'elev\'es lorsque l’on impl\'emente un L1 de plus grande taille. Dans ces cas, la zone critique s’\'etend typiquement de 2~kB \`a 16~kB, avec une croissance de l’IPC et une augmentation du pourcentage de diminution des pertes sur les donn\'ees. Pour Dijkstra, on observe aussi qu’entre 16~kB et 32~kB, l’augmentation de l’IPC est tr\`es significative, accompagn\'ee d’une diminution notable des \emph{misses} de donn\'ees en cache, ce qui est particuli\`erement important pour Dijkstra compte tenu de la mani\`ere dont les acc\`es m\'emoire se produisent, en lien avec les structures de donn\'ees employ\'ees par l’algorithme.

Cette diff\'erence par rapport au Cortex-A7 s’explique par une micro-architecture plus agressive, dot\'ee d’une largeur d’ex\'ecution plus importante, de buffers plus profonds et d’une capacit\'e sup\'erieure \`a exploiter le parall\'elisme d’instruction. Dans ces conditions, la latence m\'emoire devient un frein majeur d\`es que le cache est trop petit, car le c\oe{}ur a la capacit\'e de remplir rapidement ses fen\^etres d’instruction et d’exposer davantage de d\'ependances m\'emoire. Un L1 plus grand r\'eduit ces latences apparentes et permet au c\oe{}ur de maintenir un d\'ebit \'elev\'e, d’o\`u les gains d’IPC plus importants observ\'es pour Dijkstra.

Les diminutions de taux de \emph{miss} suivent aussi une courbe caract\'eristique : la I-cache b\'en\'eficie tr\`es t\^ot de l’augmentation de capacit\'e, car le code critique est rapidement captur\'e ; la D-cache continue \`a s’am\'eliorer jusqu’\`a 16~kB et au-del\`a, car Dijkstra, avec ses acc\`es irr\'eguliers et son \emph{working set} de donn\'ees dispers\'e, g\'en\`ere de nombreux d\'efauts de capacit\'e et de conflit lorsque le cache est trop petit.

La pr\'esence d’une ligne de 64~octets sur A15 augmente l’efficacit\'e de la localit\'e spatiale pour certains acc\`es s\'equentiels, ce qui peut contribuer \`a acc\'el\'erer la baisse des taux de \emph{miss} pour des tailles interm\'ediaires. Cette taille de ligne plus large peut toutefois amplifier le co\^ut d’un \emph{miss} individuel, ce qui rend la zone critique particuli\`erement sensible au dimensionnement du L1. L’associativit\'e 2-ways r\'eduit une partie des conflits, mais la densit\'e d’acc\`es du jeu de donn\'ees \emph{large} fait encore appara\^\i tre des collisions lorsque le cache est trop petit, d’o\`u les gains importants observ\'es entre 2~kB et 8~kB.

La distinction entre Dijkstra \emph{small} et Dijkstra \emph{large} reste visible : le jeu de donn\'ees \emph{large} profite davantage des tailles interm\'ediaires, mais la convergence vers la saturation se produit dans les deux cas, indiquant que la majeure partie du \emph{working set} pertinent finit par \^etre contenue dans le L1 ou par \^etre amortie par les m\'ecanismes de pr\'ediction et de pr\'echargement implicites du pipeline.

Dans le cas de Blowfish, le comportement est similaire \`a celui de Dijkstra, dans le sens o\`u l’augmentation de l’IPC se maintient jusqu’\`a atteindre un point d’inflexion apparent autour de 32~kB. \`A partir de cette taille, la saturation de la diminution des pertes dans la D-cache laisse pr\'evoir un ralentissement, voire un stagnation, des gains d’IPC. N\'eanmoins, il convient de souligner que, bien que les gains soient sup\'erieurs \`a ceux obtenus sur A7, ils n’atteignent qu’environ 40\% par rapport \`a l’IPC de la configuration de r\'ef\'erence avec un L1 de 1~kB.

Cela s’explique par la nature essentiellement calculatoire de l’algorithme et par la r\'egularit\'e de ses acc\`es, qui rendent les d\'efauts de cache moins fr\'equents d\`es qu’une petite capacit\'e est disponible ; l’augmentation de L1 a donc un impact limit\'e. Cette lecture met en \'evidence une logique d’optimisation diff\'erenci\'ee : un L1 plus grand est pertinent lorsque la charge de travail pr\'esente des acc\`es irr\'eguliers et une faible localit\'e de donn\'ees, tandis qu’une charge plus r\'eguli\`ere et calculatoire atteint rapidement la saturation, rendant l’augmentation de capacit\'e moins justifiable en termes de surface et d’\'energie.

La coh\'erence des tendances sur A15 indique que le comportement est robuste \`a la variation de taille et qu’il est possible d’identifier un compromis autour de 16~kB offrant un bon \'equilibre entre gain de performance et co\^ut en surface, m\^eme si la saturation finale se situe vers 32~kB. On peut \'egalement interpr\'eter ces tendances au regard de la hi\'erarchie m\'emoire globale : lorsque le L1 est petit, la D-cache d\'el\`egue plus souvent vers le L2, et m\^eme si le L2 pr\'esente des taux de d\'efauts faibles, la simple latence d’acc\`es suffit \`a d\'egrader l’IPC sur un c\oe{}ur aussi large. \`A l’inverse, quand le L1 augmente, la pression sur le L2 diminue, ce qui stabilise le temps de service et rend les files de chargement moins congestionn\'ees. Cette stabilisation r\'eduit aussi les variations d’IPC entre ex\'ecutions, signe que la phase de calcul redevient dominante.

En somme, en tenant compte de l’effet de saturation observ\'e en fonction de la taille du L1, la configuration retenue est de 32~kB. Il s’agit du pointe offrant le meilleur compromis performance/surface pour ce profil architectural, et ce, pour les deux applications.
